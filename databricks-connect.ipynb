{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test databricks-connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting databricks-connect\n",
      "  Using cached databricks_connect-15.4.2-py2.py3-none-any.whl (2.3 MB)\n",
      "Collecting databricks-sdk>=0.29.0\n",
      "  Using cached databricks_sdk-0.35.0-py3-none-any.whl (568 kB)\n",
      "Collecting googleapis-common-protos>=1.56.4\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Collecting grpcio-status>=1.59.3\n",
      "  Using cached grpcio_status-1.67.0-py3-none-any.whl (14 kB)\n",
      "Collecting grpcio>=1.59.3\n",
      "  Using cached grpcio-1.67.0-cp311-cp311-win_amd64.whl (4.4 MB)\n",
      "Collecting numpy<2,>=1.15\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\git\\dbconnect-examples\\dbconnect\\lib\\site-packages (from databricks-connect) (24.1)\n",
      "Collecting pandas>=1.0.5\n",
      "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "Collecting py4j==0.10.9.7\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Collecting pyarrow>=4.0.0\n",
      "  Using cached pyarrow-17.0.0-cp311-cp311-win_amd64.whl (25.2 MB)\n",
      "Collecting setuptools>=68.0.0\n",
      "  Using cached setuptools-75.2.0-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: six in c:\\git\\dbconnect-examples\\dbconnect\\lib\\site-packages (from databricks-connect) (1.16.0)\n",
      "Collecting requests<3,>=2.28.1\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting google-auth~=2.0\n",
      "  Using cached google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2\n",
      "  Using cached protobuf-5.28.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\git\\dbconnect-examples\\dbconnect\\lib\\site-packages (from pandas>=1.0.5->databricks-connect) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl (101 kB)\n",
      "     -------------------------------------- 101.8/101.8 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pytz, py4j, urllib3, tzdata, setuptools, pyasn1, protobuf, numpy, idna, grpcio, charset-normalizer, certifi, cachetools, rsa, requests, pyasn1-modules, pyarrow, pandas, googleapis-common-protos, grpcio-status, google-auth, databricks-sdk, databricks-connect\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "Successfully installed cachetools-5.5.0 certifi-2024.8.30 charset-normalizer-3.4.0 databricks-connect-15.4.2 databricks-sdk-0.35.0 google-auth-2.35.0 googleapis-common-protos-1.65.0 grpcio-1.67.0 grpcio-status-1.67.0 idna-3.10 numpy-1.26.4 pandas-2.2.3 protobuf-5.28.2 py4j-0.10.9.7 pyarrow-17.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pytz-2024.2 requests-2.32.3 rsa-4.9 setuptools-75.2.0 tzdata-2024.2 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install databricks-connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from databricks.connect import DatabricksSession\n",
    "spark = DatabricksSession.builder.profile('WORKSPACEM2M').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=0),\n",
       " Row(id=1),\n",
       " Row(id=2),\n",
       " Row(id=3),\n",
       " Row(id=4),\n",
       " Row(id=5),\n",
       " Row(id=6),\n",
       " Row(id=7),\n",
       " Row(id=8),\n",
       " Row(id=9)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.range(10).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbconnect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
