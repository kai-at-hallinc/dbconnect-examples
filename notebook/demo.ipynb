{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DatabricksSession classâ€™s remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "from utils import secrets\n",
    "\n",
    "# Set the host, token, and cluster_id fields in DatabricksSession.builder.remote.\n",
    "spark = DatabricksSession.builder.remote(\n",
    "   host       = f'{secrets.retrieve(\"host\")}',\n",
    "   token      = f'{secrets.retrieve(\"token\")}',\n",
    "   cluster_id = f'{secrets.retrieve(\"cluster_id\")}'\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+-------------+-----------+----------+-----------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|trip_distance|fare_amount|pickup_zip|dropoff_zip|\n",
      "+--------------------+---------------------+-------------+-----------+----------+-----------+\n",
      "| 2016-02-14 16:52:13|  2016-02-14 17:16:04|         4.94|       19.0|     10282|      10171|\n",
      "| 2016-02-04 18:44:19|  2016-02-04 18:46:00|         0.28|        3.5|     10110|      10110|\n",
      "| 2016-02-17 17:13:57|  2016-02-17 17:17:55|          0.7|        5.0|     10103|      10023|\n",
      "| 2016-02-18 10:36:07|  2016-02-18 10:41:45|          0.8|        6.0|     10022|      10017|\n",
      "| 2016-02-22 14:14:41|  2016-02-22 14:31:52|         4.51|       17.0|     10110|      10282|\n",
      "+--------------------+---------------------+-------------+-----------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.table(\"samples.nyctaxi.trips\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType\n",
    "from datetime import date\n",
    "\n",
    "# create databricks.connect session with profile\n",
    "spark = DatabricksSession.builder.profile(\"vscode\").getOrCreate()\n",
    "\n",
    "# Create a Spark DataFrame consisting of high and low temperatures by airport code and date.\n",
    "schema = StructType([\n",
    "  StructField('AirportCode', StringType(), False),\n",
    "  StructField('Date', DateType(), False),\n",
    "  StructField('TempHighF', IntegerType(), False),\n",
    "  StructField('TempLowF', IntegerType(), False)\n",
    "])\n",
    "\n",
    "data = [\n",
    "  [ 'BLI', date(2021, 4, 3), 52, 43],\n",
    "  [ 'BLI', date(2021, 4, 2), 50, 38],\n",
    "  [ 'BLI', date(2021, 4, 1), 52, 41],\n",
    "  [ 'PDX', date(2021, 4, 3), 64, 45],\n",
    "  [ 'PDX', date(2021, 4, 2), 61, 41],\n",
    "  [ 'PDX', date(2021, 4, 1), 66, 39],\n",
    "  [ 'SEA', date(2021, 4, 3), 57, 43],\n",
    "  [ 'SEA', date(2021, 4, 2), 54, 39],\n",
    "  [ 'SEA', date(2021, 4, 1), 56, 41]\n",
    "]\n",
    "\n",
    "temps = spark.createDataFrame(data, schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a table on the Databricks main catalog\n",
    "\n",
    "spark.sql('USE main.default') # Set the default database by convention\n",
    "spark.sql('DROP TABLE IF EXISTS main.default.temps_table')\n",
    "temps.write.saveAsTable('main.default.temps_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Solarize_Light2',\n",
       " '_classic_test_patch',\n",
       " '_mpl-gallery',\n",
       " '_mpl-gallery-nogrid',\n",
       " 'bmh',\n",
       " 'classic',\n",
       " 'dark_background',\n",
       " 'fast',\n",
       " 'fivethirtyeight',\n",
       " 'ggplot',\n",
       " 'grayscale',\n",
       " 'seaborn-v0_8',\n",
       " 'seaborn-v0_8-bright',\n",
       " 'seaborn-v0_8-colorblind',\n",
       " 'seaborn-v0_8-dark',\n",
       " 'seaborn-v0_8-dark-palette',\n",
       " 'seaborn-v0_8-darkgrid',\n",
       " 'seaborn-v0_8-deep',\n",
       " 'seaborn-v0_8-muted',\n",
       " 'seaborn-v0_8-notebook',\n",
       " 'seaborn-v0_8-paper',\n",
       " 'seaborn-v0_8-pastel',\n",
       " 'seaborn-v0_8-poster',\n",
       " 'seaborn-v0_8-talk',\n",
       " 'seaborn-v0_8-ticks',\n",
       " 'seaborn-v0_8-white',\n",
       " 'seaborn-v0_8-whitegrid',\n",
       " 'tableau-colorblind10']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the default style\n",
    "plt.style.use( 'seaborn-v0_8-whitegrid') \n",
    "\n",
    "# Query the table on the Databricks cluster\n",
    "df_temps = spark.sql(\n",
    "    \"SELECT * FROM temps_table \" \\\n",
    "    \"WHERE AirportCode != 'BLI' AND Date > '2021-04-01' \" \\\n",
    "    \"GROUP BY AirportCode, Date, TempHighF, TempLowF \" \\\n",
    "    \"ORDER BY TempHighF DESC\")\n",
    "\n",
    "df_temps.toPandas().plot(kind='bar', x='AirportCode', y=['TempHighF', 'TempLowF'],figsize=(6, 3), title='High and Low Temperatures by Airport Code and Date');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up by deleting the table from the Databricks cluster.\n",
    "spark.sql('DROP TABLE temps_table')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databricks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
